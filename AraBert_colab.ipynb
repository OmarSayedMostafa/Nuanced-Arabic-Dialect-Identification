{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AraBert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO0QGfAxOjo0",
        "outputId": "388583df-315e-43bf-8fe6-e4f1474615d2"
      },
      "source": [
        "!pip install plot-keras-history transformers babel"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting plot-keras-history\n",
            "  Downloading https://files.pythonhosted.org/packages/b1/d9/95c2a5bb533fc5cc0c6d99bc4c37c61c8cc6a7a1719b65ea659b2c3a7e2b/plot_keras_history-1.1.27.tar.gz\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: babel in /usr/local/lib/python3.6/dist-packages (2.9.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from plot-keras-history) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from plot-keras-history) (1.1.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from plot-keras-history) (1.4.1)\n",
            "Collecting sanitize_ml_labels\n",
            "  Downloading https://files.pythonhosted.org/packages/99/8e/c11845c546742bd2c97c33bad1eccb0c71e4962d91d9d02d32ee5ad985a8/sanitize_ml_labels-1.0.24.tar.gz\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 54.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 34.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->plot-keras-history) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->plot-keras-history) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->plot-keras-history) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->plot-keras-history) (2.8.1)\n",
            "Collecting compress_json\n",
            "  Downloading https://files.pythonhosted.org/packages/c0/9d/1a79dbc3b9d69c57be363b4cc8bd6f278f919a0973f46c7bb831438c9333/compress_json-1.0.4.tar.gz\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: plot-keras-history, sanitize-ml-labels, sacremoses, compress-json\n",
            "  Building wheel for plot-keras-history (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for plot-keras-history: filename=plot_keras_history-1.1.27-cp36-none-any.whl size=7333 sha256=4661fc106fcdc93bdafe2362eebfd3f7e0a046113f09306987811ae90fd70c0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/9e/e3/6cde1b6b6141b044c692d88980f26c4fe7806cc92ddd009c8c\n",
            "  Building wheel for sanitize-ml-labels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sanitize-ml-labels: filename=sanitize_ml_labels-1.0.24-cp36-none-any.whl size=7000 sha256=5c4b3125d01177db07df96c913c8d75f767445fcbc1b3daf553a256ea433344e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/3b/5d/f2fb3eff7f2fe268463b91a825816a07cd8458c4fe359f034a\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=13ea1773e8ad452defc183038a0d6e250374cd029ffed2c977b46711c6cfdef7\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "  Building wheel for compress-json (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for compress-json: filename=compress_json-1.0.4-cp36-none-any.whl size=4585 sha256=70f4d65bc98f8f7a409e8b4d6448b3d25d268077b39cd056dd67f13ce8e4834d\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/ec/21/51460dd508e4a152c0643946c21fae84eb3391171164d35745\n",
            "Successfully built plot-keras-history sanitize-ml-labels sacremoses compress-json\n",
            "Installing collected packages: compress-json, sanitize-ml-labels, plot-keras-history, sacremoses, tokenizers, transformers\n",
            "Successfully installed compress-json-1.0.4 plot-keras-history-1.1.27 sacremoses-0.0.43 sanitize-ml-labels-1.0.24 tokenizers-0.9.4 transformers-4.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70xT5-M-LQPX",
        "outputId": "e420eb5b-8fda-4e9d-b87e-2fe1eccff7cc"
      },
      "source": [
        "!git clone https://github.com/OmarSayedMostafa/Nuanced-Arabic-Dialect-Identification.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Nuanced-Arabic-Dialect-Identification'...\n",
            "remote: Enumerating objects: 192, done.\u001b[K\n",
            "remote: Counting objects: 100% (192/192), done.\u001b[K\n",
            "remote: Compressing objects: 100% (140/140), done.\u001b[K\n",
            "remote: Total 192 (delta 102), reused 124 (delta 46), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (192/192), 8.40 MiB | 6.60 MiB/s, done.\n",
            "Resolving deltas: 100% (102/102), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBxkcGx0LT-P",
        "outputId": "2fb10f51-3578-444e-9d14-7fec4544684d"
      },
      "source": [
        "cd Nuanced-Arabic-Dialect-Identification/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Nuanced-Arabic-Dialect-Identification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC_hYT3vIqVP"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import classification_report, f1_score"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7qMojB0Ka1R"
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "train_data_path = './cleaned_data/cleaned_train_data_for_subtask1.csv'\n",
        "test_data_path = './cleaned_data/cleaned_test_data_for_subtask1.csv'\n",
        "\n",
        "train_dataframe = pd.read_csv(train_data_path)\n",
        "test_dataframe = pd.read_csv(test_data_path)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NVURBYicLxAy",
        "outputId": "a62bf596-3e7a-4475-adb3-279b274b823a"
      },
      "source": [
        "train_dataframe.head(30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#1_tweetid</th>\n",
              "      <th>#2_tweet</th>\n",
              "      <th>#3_country_label</th>\n",
              "      <th>#2_tweet_clean_V0</th>\n",
              "      <th>#2_tweet_clean_V1</th>\n",
              "      <th>#2_tweet_clean_V2</th>\n",
              "      <th>#2_tweet_clean_V3</th>\n",
              "      <th>#classes_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TRAIN_0</td>\n",
              "      <td>حاجة حلوة اكيد</td>\n",
              "      <td>Egypt</td>\n",
              "      <td>حاجة حلوة اكيد</td>\n",
              "      <td>حاجه حلوه اكيد</td>\n",
              "      <td>حاجه حلوه اكيد</td>\n",
              "      <td>حاجه حلوه اكيد</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TRAIN_1</td>\n",
              "      <td>عم بشتغلوا للشعب الاميركي اما نحن يكذبوا ويغشوا ويسرقوا ويقتلو شعوبهم ويعملوا لصالح اعدائهم</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>عم بشتغلوا للشعب الاميركي اما نحن يكذبوا ويغشوا ويسرقوا ويقتلو شعوبهم ويعملوا لصالح اعدائهم</td>\n",
              "      <td>عم بشتغلوا لشعب الاميركي اما نحن يكذبوا ويغشوا ويسرقوا ويقتلو شعوبهم ويعملوا لصالح اعداهم</td>\n",
              "      <td>عم بشتغلوا لشعب الاميركي يكذبوا ويغشوا ويسرقوا ويقتلو شعوبهم ويعملوا لصالح اعداهم</td>\n",
              "      <td>عم بشتغلوا لشعب الاميركي يكذبوا ويغشوا ويسرقوا ويقتلو شعوبهم ويعملوا لصالح اعداهم</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TRAIN_2</td>\n",
              "      <td>ابشر طال عمرك</td>\n",
              "      <td>Saudi_Arabia</td>\n",
              "      <td>ابشر طال عمرك</td>\n",
              "      <td>ابشر طال عمرك</td>\n",
              "      <td>ابشر طال عمرك</td>\n",
              "      <td>ابشر طال عمرك</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TRAIN_3</td>\n",
              "      <td>منطق 2017: أنا والغريب علي إبن عمي وأنا والغريب وإبن عمي علي أخويا. #قطع_العلاقات_مع_قطر #موريتانيا_مع_قطر</td>\n",
              "      <td>Mauritania</td>\n",
              "      <td>منطق  أنا والغريب علي إبن عمي وأنا والغريب وإبن عمي علي أخويا قطع العلاقات مع قطر موريتانيا مع قطر</td>\n",
              "      <td>منطق انا والغريب علي ابن عمي وانا والغريب وابن عمي علي اخويا قطع العلاقات مع قطر موريتانيا مع قطر</td>\n",
              "      <td>منطق والغريب ابن عمي وانا والغريب وابن عمي اخويا قطع العلاقات قطر موريتانيا قطر</td>\n",
              "      <td>منطق والغريب ابن عمي وانا وابن اخويا قطع العلاقات قطر موريتانيا</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TRAIN_4</td>\n",
              "      <td>شهرين وتروح والباقي غير صيف ملينا</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>شهرين وتروح والباقي غير صيف ملينا</td>\n",
              "      <td>شهرين وتروح والباقي غير صيف ملينا</td>\n",
              "      <td>شهرين وتروح والباقي صيف ملينا</td>\n",
              "      <td>شهرين وتروح والباقي صيف ملينا</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TRAIN_5</td>\n",
              "      <td>يابنتى والله ما حد متغاظ ولا مفروس منك ولا بيحسدك انتى عره اساسا.</td>\n",
              "      <td>Syria</td>\n",
              "      <td>يابنتى والله ما حد متغاظ ولا مفروس منك ولا بيحسدك انتى عره اساسا</td>\n",
              "      <td>يابنتى واله ما حد متغاظ ولا مفروس منك ولا بيحسدك انتى عره اساسا</td>\n",
              "      <td>يابنتى واله حد متغاظ مفروس منك بيحسدك انتى عره اساسا</td>\n",
              "      <td>يابنتى واله حد متغاظ مفروس منك بيحسدك انتى عره اساسا</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>TRAIN_6</td>\n",
              "      <td>نفس الوقت بأكد على صاحبتي ان اي هدف هتحطه وتخططله هيبوظ والأفضل التشاؤم واننا نتوقع الأسوء دايما والفشل عشان منعشمش نفسنا ع الفاضي</td>\n",
              "      <td>Egypt</td>\n",
              "      <td>نفس الوقت بأكد على صاحبتي ان اي هدف هتحطه وتخططله هيبوظ والأفضل التشاؤم واننا نتوقع الأسوء دايما والفشل عشان منعشمش نفسنا ع الفاضي</td>\n",
              "      <td>نفس الوقت باكد على صاحبتي ان اي هدف هتحطه وتخطله هيبوظ والافضل التشام وانا نتوقع الاسوء دايما والفشل عشان منعشمش نفسنا الفاضي</td>\n",
              "      <td>باكد صاحبتي هدف هتحطه وتخطله هيبوظ والافضل التشام وانا نتوقع الاسوء دايما والفشل عشان منعشمش نفسنا الفاضي</td>\n",
              "      <td>باكد صاحبتي هدف هتحطه وتخطله هيبوظ والافضل التشام وانا نتوقع الاسوء دايما والفشل عشان منعشمش نفسنا الفاضي</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>TRAIN_7</td>\n",
              "      <td>م تبطلي خرا بقا علشان مطلعهوش عليكي احترمي نفسك URL  …</td>\n",
              "      <td>Egypt</td>\n",
              "      <td>م تبطلي خرا بقا علشان مطلعهوش عليكي احترمي نفسك</td>\n",
              "      <td>تبطلي خرا بقا علشان مطلعهوش عليكي احترمي نفسك</td>\n",
              "      <td>تبطلي خرا بقا علشان مطلعهوش عليكي احترمي نفسك</td>\n",
              "      <td>تبطلي خرا بقا علشان مطلعهوش عليكي احترمي نفسك</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>TRAIN_8</td>\n",
              "      <td>ما يله دخل !</td>\n",
              "      <td>Oman</td>\n",
              "      <td>ما يله دخل</td>\n",
              "      <td>ما يله دخل</td>\n",
              "      <td>يله دخل</td>\n",
              "      <td>يله دخل</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>TRAIN_9</td>\n",
              "      <td>هو حلو بس يتخربط ع طلاب المدراس ليك مايغيرونه عدنا</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>هو حلو بس يتخربط ع طلاب المدراس ليك مايغيرونه عدنا</td>\n",
              "      <td>هو حلو بس يتخربط طلاب المدراس ليك مايغيرونه عدنا</td>\n",
              "      <td>حلو يتخربط طلاب المدراس ليك مايغيرونه عدنا</td>\n",
              "      <td>حلو يتخربط طلاب المدراس ليك مايغيرونه عدنا</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>TRAIN_10</td>\n",
              "      <td>أي عرفتو، ماعندوش مصداقية بصراحة</td>\n",
              "      <td>Tunisia</td>\n",
              "      <td>أي عرفتو ماعندوش مصداقية بصراحة</td>\n",
              "      <td>اي عرفتو ماعندوش مصداقيه بصراحه</td>\n",
              "      <td>عرفتو ماعندوش مصداقيه بصراحه</td>\n",
              "      <td>عرفتو ماعندوش مصداقيه بصراحه</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>TRAIN_11</td>\n",
              "      <td>بتتذكري مسلسل نورا هيك بتذكر كان اسمها في</td>\n",
              "      <td>Lebanon</td>\n",
              "      <td>بتتذكري مسلسل نورا هيك بتذكر كان اسمها في</td>\n",
              "      <td>بتذكري مسلسل نورا هيك بتذكر كان اسمها في</td>\n",
              "      <td>بتذكري مسلسل نورا هيك بتذكر اسمها</td>\n",
              "      <td>بتذكري مسلسل نورا هيك بتذكر اسمها</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>TRAIN_12</td>\n",
              "      <td>أحمد ربي ديجا كي يجي واحد منهم في الوقت</td>\n",
              "      <td>Tunisia</td>\n",
              "      <td>أحمد ربي ديجا كي يجي واحد منهم في الوقت</td>\n",
              "      <td>احمد ربي ديجا كي يجي واحد منهم في الوقت</td>\n",
              "      <td>احمد ربي ديجا كي يجي منهم</td>\n",
              "      <td>احمد ربي ديجا كي يجي منهم</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>TRAIN_13</td>\n",
              "      <td>يسطا لازم قريب خد بالك</td>\n",
              "      <td>Tunisia</td>\n",
              "      <td>يسطا لازم قريب خد بالك</td>\n",
              "      <td>يسطا لازم قريب خد بالك</td>\n",
              "      <td>يسطا لازم قريب خد بالك</td>\n",
              "      <td>يسطا لازم قريب خد بالك</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>TRAIN_14</td>\n",
              "      <td>نزعل و الله لو تريكه مرضش</td>\n",
              "      <td>Tunisia</td>\n",
              "      <td>نزعل و الله لو تريكه مرضش</td>\n",
              "      <td>نزعل اله لو تريكه مرضش</td>\n",
              "      <td>نزعل اله تريكه مرضش</td>\n",
              "      <td>نزعل اله تريكه مرضش</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>TRAIN_15</td>\n",
              "      <td>فخري وتاج راسي هالنونا والله URL</td>\n",
              "      <td>Morocco</td>\n",
              "      <td>فخري وتاج راسي هالنونا والله</td>\n",
              "      <td>فخري وتاج راسي هالنونا واله</td>\n",
              "      <td>فخري وتاج راسي هالنونا واله</td>\n",
              "      <td>فخري وتاج راسي هالنونا واله</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>TRAIN_16</td>\n",
              "      <td>مال صور ' تاريخ ١٨-١٩ /٧ . URL</td>\n",
              "      <td>Oman</td>\n",
              "      <td>مال صور  تاريخ ١٨ ١٩ ٧</td>\n",
              "      <td>مال صور تاريخ</td>\n",
              "      <td>مال صور تاريخ</td>\n",
              "      <td>مال صور تاريخ</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>TRAIN_17</td>\n",
              "      <td>فورنو كهرباء نوع كوبر نضيف بسعر مغري وممتاز El Oued إعلانات مبوبة في الجزائر | Ssoug  URL …</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>فورنو كهرباء نوع كوبر نضيف بسعر مغري وممتاز   إعلانات مبوبة في الجزائر</td>\n",
              "      <td>فورنو كهرباء نوع كوبر نضيف بسعر مغري ومتاز اعلانات مبوبه في الجزار</td>\n",
              "      <td>فورنو كهرباء نوع كوبر نضيف بسعر مغري ومتاز اعلانات مبوبه الجزار</td>\n",
              "      <td>فورنو كهرباء نوع كوبر نضيف بسعر مغري ومتاز اعلانات مبوبه الجزار</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>TRAIN_18</td>\n",
              "      <td>لا حبيتي اني مااسمع صوات حمير هنق هنق</td>\n",
              "      <td>Djibouti</td>\n",
              "      <td>لا حبيتي اني مااسمع صوات حمير هنق هنق</td>\n",
              "      <td>لا حبيتي اني ماسمع صوات حمير هنق هنق</td>\n",
              "      <td>حبيتي اني ماسمع صوات حمير هنق هنق</td>\n",
              "      <td>حبيتي اني ماسمع صوات حمير هنق</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>TRAIN_19</td>\n",
              "      <td>بدو يحشر حالو بين كنادر البنات ، فعلا نظرو واطي هالشخص URL  …</td>\n",
              "      <td>United_Arab_Emirates</td>\n",
              "      <td>بدو يحشر حالو بين كنادر البنات  فعلا نظرو واطي هالشخص</td>\n",
              "      <td>بدو يحشر حالو بين كنادر البنات فعلا نظرو واطي هالشخص</td>\n",
              "      <td>بدو يحشر حالو كنادر البنات فعلا نظرو واطي هالشخص</td>\n",
              "      <td>بدو يحشر حالو كنادر البنات فعلا نظرو واطي هالشخص</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>TRAIN_20</td>\n",
              "      <td>\"مقتنعه ب جمله \\\" لكل فعل رد فعل \\\" ف استحملوا يعنى\"</td>\n",
              "      <td>Egypt</td>\n",
              "      <td>مقتنعه ب جمله  لكل فعل رد فعل  ف استحملوا يعنى</td>\n",
              "      <td>مقتنعه جمله لكل فعل رد فعل استحملوا يعنى</td>\n",
              "      <td>مقتنعه جمله لكل فعل رد فعل استحملوا يعنى</td>\n",
              "      <td>مقتنعه جمله لكل فعل رد استحملوا يعنى</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>TRAIN_21</td>\n",
              "      <td>اكثر يوم حسيت فيه اني خريجه صج</td>\n",
              "      <td>Kuwait</td>\n",
              "      <td>اكثر يوم حسيت فيه اني خريجه صج</td>\n",
              "      <td>اكثر يوم حسيت فيه اني خريجه صج</td>\n",
              "      <td>حسيت اني خريجه صج</td>\n",
              "      <td>حسيت اني خريجه صج</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>TRAIN_22</td>\n",
              "      <td>بوصوفة مشى والصراحة غيخلي بلاصتو ولكن المستقبل هو زياش متنساش راه اول كاس افريقيا غيلعبها</td>\n",
              "      <td>Morocco</td>\n",
              "      <td>بوصوفة مشى والصراحة غيخلي بلاصتو ولكن المستقبل هو زياش متنساش راه اول كاس افريقيا غيلعبها</td>\n",
              "      <td>بوصوفه مشى والصراحه غيخلي بلاصتو ولكن المستقبل هو زياش متنساش راه اول كاس افريقيا غيلعبها</td>\n",
              "      <td>بوصوفه مشى والصراحه غيخلي بلاصتو المستقبل زياش متنساش راه كاس افريقيا غيلعبها</td>\n",
              "      <td>بوصوفه مشى والصراحه غيخلي بلاصتو المستقبل زياش متنساش راه كاس افريقيا غيلعبها</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>TRAIN_23</td>\n",
              "      <td>USER  والله بجد اللقب هيتشرف بعباس</td>\n",
              "      <td>Syria</td>\n",
              "      <td>والله بجد اللقب هيتشرف بعباس</td>\n",
              "      <td>واله بجد القب هيتشرف بعباس</td>\n",
              "      <td>واله بجد القب هيتشرف بعباس</td>\n",
              "      <td>واله بجد القب هيتشرف بعباس</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>TRAIN_24</td>\n",
              "      <td>أموت في حبجج؛ خيتي.</td>\n",
              "      <td>Oman</td>\n",
              "      <td>أموت في حبجج خيتي</td>\n",
              "      <td>اموت في حبج خيتي</td>\n",
              "      <td>اموت حبج خيتي</td>\n",
              "      <td>اموت حبج خيتي</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>TRAIN_25</td>\n",
              "      <td>وش للتبديل الغبي ذا؟؟؟؟؟؟</td>\n",
              "      <td>Saudi_Arabia</td>\n",
              "      <td>وش للتبديل الغبي ذا</td>\n",
              "      <td>وش لتبديل الغبي ذا</td>\n",
              "      <td>وش لتبديل الغبي</td>\n",
              "      <td>وش لتبديل الغبي</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>TRAIN_26</td>\n",
              "      <td>المصور ما عقلهاش</td>\n",
              "      <td>Tunisia</td>\n",
              "      <td>المصور ما عقلهاش</td>\n",
              "      <td>المصور ما عقلهاش</td>\n",
              "      <td>المصور عقلهاش</td>\n",
              "      <td>المصور عقلهاش</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>TRAIN_27</td>\n",
              "      <td>مادار في بالي الخالي اتعلق بغالي واضيع انا في الدرب وشصار لهالگلب حب وعشگ وانحب واني ادري انه صعب وشصار شنو...  URL</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>مادار في بالي الخالي اتعلق بغالي واضيع انا في الدرب وشصار لهالگلب حب وعشگ وانحب واني ادري انه صعب وشصار شنو</td>\n",
              "      <td>مادار في بالي الخالي اتعلق بغالي واضيع انا في الدرب وشصار لهالكلب حب وعشك وانحب واني ادري انه صعب وشصار شنو</td>\n",
              "      <td>مادار بالي الخالي اتعلق بغالي واضيع الدرب وشصار لهالكلب حب وعشك وانحب واني ادري صعب وشصار شنو</td>\n",
              "      <td>مادار بالي الخالي اتعلق بغالي واضيع الدرب وشصار لهالكلب حب وعشك وانحب واني ادري صعب شنو</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>TRAIN_28</td>\n",
              "      <td>لما اقول لبنت طيزك حمرا دي مش شتيمة دا مدح عظيم لو تعلمون</td>\n",
              "      <td>Egypt</td>\n",
              "      <td>لما اقول لبنت طيزك حمرا دي مش شتيمة دا مدح عظيم لو تعلمون</td>\n",
              "      <td>لما اقول لبنت طيزك حمرا دي مش شتيمه دا مدح عظيم لو تعلمون</td>\n",
              "      <td>اقول لبنت طيزك حمرا دي مش شتيمه دا مدح عظيم تعلمون</td>\n",
              "      <td>اقول لبنت طيزك حمرا دي مش شتيمه دا مدح عظيم تعلمون</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>TRAIN_29</td>\n",
              "      <td>ماحس الي يالسه ترمسني ميثوه (:</td>\n",
              "      <td>United_Arab_Emirates</td>\n",
              "      <td>ماحس الي يالسه ترمسني ميثوه</td>\n",
              "      <td>ماحس الي يالسه ترمسني ميثوه</td>\n",
              "      <td>ماحس يالسه ترمسني ميثوه</td>\n",
              "      <td>ماحس يالسه ترمسني ميثوه</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   #1_tweetid  ... #classes_id\n",
              "0   TRAIN_0    ...  0         \n",
              "1   TRAIN_1    ...  1         \n",
              "2   TRAIN_2    ...  2         \n",
              "3   TRAIN_3    ...  3         \n",
              "4   TRAIN_4    ...  4         \n",
              "5   TRAIN_5    ...  5         \n",
              "6   TRAIN_6    ...  0         \n",
              "7   TRAIN_7    ...  0         \n",
              "8   TRAIN_8    ...  6         \n",
              "9   TRAIN_9    ...  1         \n",
              "10  TRAIN_10   ...  7         \n",
              "11  TRAIN_11   ...  8         \n",
              "12  TRAIN_12   ...  7         \n",
              "13  TRAIN_13   ...  7         \n",
              "14  TRAIN_14   ...  7         \n",
              "15  TRAIN_15   ...  9         \n",
              "16  TRAIN_16   ...  6         \n",
              "17  TRAIN_17   ...  4         \n",
              "18  TRAIN_18   ...  10        \n",
              "19  TRAIN_19   ...  11        \n",
              "20  TRAIN_20   ...  0         \n",
              "21  TRAIN_21   ...  12        \n",
              "22  TRAIN_22   ...  9         \n",
              "23  TRAIN_23   ...  5         \n",
              "24  TRAIN_24   ...  6         \n",
              "25  TRAIN_25   ...  2         \n",
              "26  TRAIN_26   ...  7         \n",
              "27  TRAIN_27   ...  1         \n",
              "28  TRAIN_28   ...  0         \n",
              "29  TRAIN_29   ...  11        \n",
              "\n",
              "[30 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SuVE8s86C7D"
      },
      "source": [
        "classes_names = train_dataframe['#3_country_label'].unique().tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhUXUhW16Fbi",
        "outputId": "4263b3bb-56d6-4388-99ff-eb5614e82973"
      },
      "source": [
        "classes_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Egypt',\n",
              " 'Iraq',\n",
              " 'Saudi_Arabia',\n",
              " 'Mauritania',\n",
              " 'Algeria',\n",
              " 'Syria',\n",
              " 'Oman',\n",
              " 'Tunisia',\n",
              " 'Lebanon',\n",
              " 'Morocco',\n",
              " 'Djibouti',\n",
              " 'United_Arab_Emirates',\n",
              " 'Kuwait',\n",
              " 'Libya',\n",
              " 'Bahrain',\n",
              " 'Qatar',\n",
              " 'Yemen',\n",
              " 'Palestine',\n",
              " 'Jordan',\n",
              " 'Somalia',\n",
              " 'Sudan']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gsjKH5cOKJN"
      },
      "source": [
        "train_x = train_dataframe['#2_tweet_clean_V0'].tolist()\n",
        "train_y = train_dataframe['#classes_id'].tolist()\n",
        "\n",
        "test_x = test_dataframe['#2_tweet_clean_V0'].tolist()\n",
        "test_y = test_dataframe['#classes_id'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvNSEu8HOStw"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bashar-talafha/multi-dialect-bert-base-arabic\")\n",
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_x,\n",
        "    max_length = 80,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    test_x,\n",
        "    max_length = 80,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNyznyQHOWGg"
      },
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_y)\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f4fVJG36RET"
      },
      "source": [
        "# train_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ck_IudiPykX"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "#define a batch size\n",
        "batch_size = 64\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3R2HDinQDFq"
      },
      "source": [
        "bert = AutoModel.from_pretrained(\"bashar-talafha/multi-dialect-bert-base-arabic\")\n",
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6djfrF1XF3X8"
      },
      "source": [
        "batch =  next(iter(train_dataloader)) \n",
        "    # # progress update after every 50 batches.\n",
        "    # # push the batch to gpu\n",
        "    # # batch = [r.to(device) for r in batch]\n",
        "sent_id, mask, labels = batch\n",
        "preds = bert(sent_id, mask)\n",
        "\n",
        "    # print(len(preds))\n",
        "\n",
        "    # break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jSADIcVH_Ex",
        "outputId": "734b684d-c4f0-4dae-a5c0-fbb2006d08c0"
      },
      "source": [
        "len(preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN672pwDH-_E",
        "outputId": "3ee96e6f-1404-467f-d309-9dac3a215449"
      },
      "source": [
        "print(preds[0].shape, preds[1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 80, 768]) torch.Size([64, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o3RFzN_HxgN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKPtQiNIQKkL"
      },
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "    def __init__(self, bert):\n",
        "      super(BERT_Arch, self).__init__()\n",
        "      self.bert = bert \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,21)\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "      x = self.fc1(cls_hs)\n",
        "      x = self.relu(x)\n",
        "      x = self.dropout(x)\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrOLxDyOQWZq"
      },
      "source": [
        "device = 'cuda'\n",
        "model = BERT_Arch(bert)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mkm3nZf3QbW2",
        "outputId": "f1fe861c-667a-4c05-a6f5-7158beb79544"
      },
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "import numpy as np\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "y = train_dataframe['#3_country_label']\n",
        "class_weights = compute_class_weight('balanced', np.unique(y), y)\n",
        "\n",
        "print(class_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5533307  4.64540421 4.6671117  0.23351927 0.36638368 2.32811633\n",
            " 2.32811633 1.55087252 0.77724662 4.6671117  1.16814258 0.66628546\n",
            " 2.33902085 4.6671117  0.46692936 5.80675526 4.6671117  0.77603878\n",
            " 1.16270303 1.5557039  2.33355585]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLUyFx23Qzj4"
      },
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  print(\"\\nEvaluating...\")\n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      # Calculate elapsed time in minutes.\n",
        "      # elapsed = format_time(time.time() - t0)\n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "    sent_id, mask, labels = batch\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "      # all_predictions.append(preds)\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "      total_loss = total_loss + loss.item()\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "      total_preds.append(preds)\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "  return avg_loss, total_preds\n",
        "\n",
        "\n",
        "\n",
        "# function to train the model\n",
        "def train():\n",
        "  global model\n",
        "  model.train()\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        "    sent_id, mask, labels = batch\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0XWxHEi6Mx6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ3RL2IYRKb8",
        "outputId": "31fd95fd-cd7f-4739-ff3a-8a7a3d2b9db5"
      },
      "source": [
        "# converting list of class weights to a tensor\n",
        "weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "# push to GPU\n",
        "weights = weights.to(device)\n",
        "# define the loss function\n",
        "# cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "cross_entropy  = nn.NLLLoss() \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 10\n",
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "  print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "  #train model\n",
        "  train_loss, _ = train()\n",
        "  #evaluate model\n",
        "  valid_loss, all_prediction = evaluate()\n",
        "  print(classification_report(val_y, np.argmax(all_prediction, axis=1), target_names=classes_names))\n",
        "  #save the best model\n",
        "  if valid_loss < best_valid_loss:\n",
        "      best_valid_loss = valid_loss\n",
        "      torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "  # append training and validation loss\n",
        "  train_losses.append(train_loss)\n",
        "  valid_losses.append(valid_loss)\n",
        "  print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "  print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.57      0.91      0.70      1041\n",
            "                Iraq       0.31      0.58      0.40       663\n",
            "        Saudi_Arabia       0.30      0.59      0.40       519\n",
            "          Mauritania       0.00      0.00      0.00        53\n",
            "             Algeria       0.45      0.37      0.41       430\n",
            "               Syria       0.21      0.12      0.15       278\n",
            "                Oman       0.29      0.03      0.06       355\n",
            "             Tunisia       0.20      0.02      0.03       172\n",
            "             Lebanon       0.17      0.04      0.07       157\n",
            "             Morocco       0.00      0.00      0.00       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.39      0.24      0.29       157\n",
            "              Kuwait       0.00      0.00      0.00       105\n",
            "               Libya       0.25      0.27      0.26       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.00      0.00      0.00       105\n",
            "           Palestine       0.00      0.00      0.00       104\n",
            "              Jordan       0.00      0.00      0.00       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.29      0.23      0.26        53\n",
            "\n",
            "            accuracy                           0.40      4997\n",
            "           macro avg       0.16      0.16      0.14      4997\n",
            "        weighted avg       0.31      0.40      0.32      4997\n",
            "\n",
            "\n",
            "Training Loss: 2.199\n",
            "Validation Loss: 2.140\n",
            "\n",
            " Epoch 2 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.56      0.92      0.70      1041\n",
            "                Iraq       0.32      0.57      0.41       663\n",
            "        Saudi_Arabia       0.34      0.40      0.37       519\n",
            "          Mauritania       0.00      0.00      0.00        53\n",
            "             Algeria       0.40      0.42      0.41       430\n",
            "               Syria       0.25      0.06      0.10       278\n",
            "                Oman       0.16      0.21      0.18       355\n",
            "             Tunisia       0.24      0.08      0.11       172\n",
            "             Lebanon       0.11      0.10      0.10       157\n",
            "             Morocco       0.00      0.00      0.00       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.31      0.26      0.28       157\n",
            "              Kuwait       0.00      0.00      0.00       105\n",
            "               Libya       0.36      0.15      0.22       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.00      0.00      0.00       105\n",
            "           Palestine       0.00      0.00      0.00       104\n",
            "              Jordan       0.00      0.00      0.00       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.30      0.36      0.33        53\n",
            "\n",
            "            accuracy                           0.39      4997\n",
            "           macro avg       0.16      0.17      0.15      4997\n",
            "        weighted avg       0.30      0.39      0.32      4997\n",
            "\n",
            "\n",
            "Training Loss: 2.079\n",
            "Validation Loss: 2.113\n",
            "\n",
            " Epoch 3 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.56      0.92      0.69      1041\n",
            "                Iraq       0.40      0.42      0.41       663\n",
            "        Saudi_Arabia       0.32      0.58      0.41       519\n",
            "          Mauritania       0.00      0.00      0.00        53\n",
            "             Algeria       0.33      0.50      0.40       430\n",
            "               Syria       0.22      0.13      0.17       278\n",
            "                Oman       0.18      0.17      0.18       355\n",
            "             Tunisia       0.12      0.01      0.01       172\n",
            "             Lebanon       0.15      0.08      0.10       157\n",
            "             Morocco       0.00      0.00      0.00       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.28      0.35      0.31       157\n",
            "              Kuwait       0.00      0.00      0.00       105\n",
            "               Libya       0.35      0.13      0.19       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.07      0.01      0.02       105\n",
            "           Palestine       0.11      0.02      0.03       104\n",
            "              Jordan       0.00      0.00      0.00       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.29      0.23      0.25        53\n",
            "\n",
            "            accuracy                           0.39      4997\n",
            "           macro avg       0.16      0.17      0.15      4997\n",
            "        weighted avg       0.30      0.39      0.33      4997\n",
            "\n",
            "\n",
            "Training Loss: 2.042\n",
            "Validation Loss: 2.119\n",
            "\n",
            " Epoch 4 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.60      0.91      0.72      1041\n",
            "                Iraq       0.35      0.52      0.42       663\n",
            "        Saudi_Arabia       0.31      0.62      0.41       519\n",
            "          Mauritania       0.00      0.00      0.00        53\n",
            "             Algeria       0.32      0.50      0.39       430\n",
            "               Syria       0.22      0.13      0.16       278\n",
            "                Oman       0.19      0.11      0.14       355\n",
            "             Tunisia       0.19      0.02      0.03       172\n",
            "             Lebanon       0.17      0.05      0.08       157\n",
            "             Morocco       0.00      0.00      0.00       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.33      0.27      0.30       157\n",
            "              Kuwait       0.00      0.00      0.00       105\n",
            "               Libya       0.36      0.10      0.15       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.32      0.09      0.14       105\n",
            "           Palestine       0.00      0.00      0.00       104\n",
            "              Jordan       0.00      0.00      0.00       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.31      0.17      0.22        53\n",
            "\n",
            "            accuracy                           0.40      4997\n",
            "           macro avg       0.17      0.17      0.15      4997\n",
            "        weighted avg       0.31      0.40      0.33      4997\n",
            "\n",
            "\n",
            "Training Loss: 2.019\n",
            "Validation Loss: 2.096\n",
            "\n",
            " Epoch 5 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.52      0.94      0.67      1041\n",
            "                Iraq       0.40      0.40      0.40       663\n",
            "        Saudi_Arabia       0.31      0.61      0.41       519\n",
            "          Mauritania       0.00      0.00      0.00        53\n",
            "             Algeria       0.38      0.45      0.41       430\n",
            "               Syria       0.22      0.14      0.17       278\n",
            "                Oman       0.20      0.14      0.17       355\n",
            "             Tunisia       0.29      0.03      0.05       172\n",
            "             Lebanon       0.14      0.10      0.12       157\n",
            "             Morocco       0.00      0.00      0.00       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.32      0.31      0.31       157\n",
            "              Kuwait       0.00      0.00      0.00       105\n",
            "               Libya       0.35      0.16      0.22       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.00      0.00      0.00       105\n",
            "           Palestine       0.00      0.00      0.00       104\n",
            "              Jordan       0.00      0.00      0.00       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.29      0.38      0.33        53\n",
            "\n",
            "            accuracy                           0.40      4997\n",
            "           macro avg       0.16      0.17      0.15      4997\n",
            "        weighted avg       0.30      0.40      0.32      4997\n",
            "\n",
            "\n",
            "Training Loss: 2.002\n",
            "Validation Loss: 2.132\n",
            "\n",
            " Epoch 6 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.56      0.93      0.70      1041\n",
            "                Iraq       0.35      0.47      0.40       663\n",
            "        Saudi_Arabia       0.32      0.49      0.39       519\n",
            "          Mauritania       0.00      0.00      0.00        53\n",
            "             Algeria       0.36      0.45      0.40       430\n",
            "               Syria       0.23      0.14      0.17       278\n",
            "                Oman       0.18      0.25      0.21       355\n",
            "             Tunisia       0.29      0.06      0.10       172\n",
            "             Lebanon       0.21      0.06      0.10       157\n",
            "             Morocco       0.00      0.00      0.00       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.32      0.32      0.32       157\n",
            "              Kuwait       0.00      0.00      0.00       105\n",
            "               Libya       0.42      0.11      0.17       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.00      0.00      0.00       105\n",
            "           Palestine       0.00      0.00      0.00       104\n",
            "              Jordan       0.00      0.00      0.00       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.34      0.32      0.33        53\n",
            "\n",
            "            accuracy                           0.39      4997\n",
            "           macro avg       0.17      0.17      0.16      4997\n",
            "        weighted avg       0.31      0.39      0.33      4997\n",
            "\n",
            "\n",
            "Training Loss: 1.986\n",
            "Validation Loss: 2.117\n",
            "\n",
            " Epoch 7 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.59      0.91      0.72      1041\n",
            "                Iraq       0.33      0.53      0.41       663\n",
            "        Saudi_Arabia       0.35      0.38      0.36       519\n",
            "          Mauritania       0.00      0.00      0.00        53\n",
            "             Algeria       0.31      0.59      0.40       430\n",
            "               Syria       0.20      0.16      0.18       278\n",
            "                Oman       0.20      0.14      0.16       355\n",
            "             Tunisia       0.21      0.03      0.06       172\n",
            "             Lebanon       0.30      0.04      0.08       157\n",
            "             Morocco       0.00      0.00      0.00       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.25      0.39      0.31       157\n",
            "              Kuwait       0.08      0.01      0.02       105\n",
            "               Libya       0.30      0.09      0.14       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.29      0.11      0.16       105\n",
            "           Palestine       0.00      0.00      0.00       104\n",
            "              Jordan       0.00      0.00      0.00       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.31      0.21      0.25        53\n",
            "\n",
            "            accuracy                           0.39      4997\n",
            "           macro avg       0.18      0.17      0.15      4997\n",
            "        weighted avg       0.31      0.39      0.33      4997\n",
            "\n",
            "\n",
            "Training Loss: 1.972\n",
            "Validation Loss: 2.097\n",
            "\n",
            " Epoch 8 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.61      0.90      0.73      1041\n",
            "                Iraq       0.36      0.47      0.41       663\n",
            "        Saudi_Arabia       0.30      0.53      0.38       519\n",
            "          Mauritania       0.38      0.06      0.10        53\n",
            "             Algeria       0.39      0.48      0.43       430\n",
            "               Syria       0.17      0.18      0.17       278\n",
            "                Oman       0.27      0.10      0.15       355\n",
            "             Tunisia       0.29      0.08      0.12       172\n",
            "             Lebanon       0.16      0.10      0.12       157\n",
            "             Morocco       0.67      0.01      0.02       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.30      0.31      0.30       157\n",
            "              Kuwait       0.15      0.04      0.06       105\n",
            "               Libya       0.27      0.25      0.26       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.00      0.00      0.00       105\n",
            "           Palestine       0.00      0.00      0.00       104\n",
            "              Jordan       1.00      0.01      0.02       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.33      0.36      0.35        53\n",
            "\n",
            "            accuracy                           0.40      4997\n",
            "           macro avg       0.27      0.18      0.17      4997\n",
            "        weighted avg       0.37      0.40      0.34      4997\n",
            "\n",
            "\n",
            "Training Loss: 1.961\n",
            "Validation Loss: 2.096\n",
            "\n",
            " Epoch 9 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.57      0.92      0.70      1041\n",
            "                Iraq       0.37      0.48      0.42       663\n",
            "        Saudi_Arabia       0.32      0.49      0.38       519\n",
            "          Mauritania       0.50      0.02      0.04        53\n",
            "             Algeria       0.40      0.41      0.41       430\n",
            "               Syria       0.18      0.20      0.19       278\n",
            "                Oman       0.23      0.16      0.19       355\n",
            "             Tunisia       0.18      0.03      0.06       172\n",
            "             Lebanon       0.27      0.06      0.09       157\n",
            "             Morocco       0.47      0.07      0.13       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.28      0.34      0.31       157\n",
            "              Kuwait       0.11      0.03      0.05       105\n",
            "               Libya       0.29      0.21      0.24       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.29      0.02      0.04       105\n",
            "           Palestine       0.12      0.01      0.02       104\n",
            "              Jordan       0.00      0.00      0.00       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.27      0.36      0.31        53\n",
            "\n",
            "            accuracy                           0.40      4997\n",
            "           macro avg       0.23      0.18      0.17      4997\n",
            "        weighted avg       0.34      0.40      0.34      4997\n",
            "\n",
            "\n",
            "Training Loss: 1.942\n",
            "Validation Loss: 2.118\n",
            "\n",
            " Epoch 10 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.59      0.91      0.71      1041\n",
            "                Iraq       0.32      0.54      0.41       663\n",
            "        Saudi_Arabia       0.35      0.40      0.38       519\n",
            "          Mauritania       0.67      0.04      0.07        53\n",
            "             Algeria       0.42      0.36      0.39       430\n",
            "               Syria       0.20      0.14      0.17       278\n",
            "                Oman       0.19      0.20      0.20       355\n",
            "             Tunisia       0.26      0.19      0.22       172\n",
            "             Lebanon       0.20      0.07      0.10       157\n",
            "             Morocco       0.47      0.03      0.06       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.30      0.35      0.32       157\n",
            "              Kuwait       0.06      0.04      0.05       105\n",
            "               Libya       0.30      0.19      0.23       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.40      0.02      0.04       105\n",
            "           Palestine       0.00      0.00      0.00       104\n",
            "              Jordan       0.00      0.00      0.00       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.32      0.40      0.35        53\n",
            "\n",
            "            accuracy                           0.40      4997\n",
            "           macro avg       0.24      0.19      0.18      4997\n",
            "        weighted avg       0.35      0.40      0.34      4997\n",
            "\n",
            "\n",
            "Training Loss: 1.934\n",
            "Validation Loss: 2.125\n",
            "\n",
            " Epoch 11 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.57      0.91      0.70      1041\n",
            "                Iraq       0.36      0.42      0.39       663\n",
            "        Saudi_Arabia       0.32      0.47      0.38       519\n",
            "          Mauritania       0.50      0.02      0.04        53\n",
            "             Algeria       0.34      0.50      0.40       430\n",
            "               Syria       0.19      0.22      0.20       278\n",
            "                Oman       0.22      0.17      0.19       355\n",
            "             Tunisia       0.26      0.08      0.12       172\n",
            "             Lebanon       0.23      0.05      0.08       157\n",
            "             Morocco       0.14      0.00      0.01       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.32      0.29      0.31       157\n",
            "              Kuwait       0.08      0.02      0.03       105\n",
            "               Libya       0.32      0.20      0.25       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.33      0.02      0.04       105\n",
            "           Palestine       0.11      0.01      0.02       104\n",
            "              Jordan       0.00      0.00      0.00       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.32      0.36      0.34        53\n",
            "\n",
            "            accuracy                           0.39      4997\n",
            "           macro avg       0.22      0.18      0.17      4997\n",
            "        weighted avg       0.33      0.39      0.34      4997\n",
            "\n",
            "\n",
            "Training Loss: 1.926\n",
            "Validation Loss: 2.118\n",
            "\n",
            " Epoch 12 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.57      0.92      0.70      1041\n",
            "                Iraq       0.39      0.41      0.40       663\n",
            "        Saudi_Arabia       0.32      0.52      0.39       519\n",
            "          Mauritania       0.50      0.04      0.07        53\n",
            "             Algeria       0.33      0.50      0.40       430\n",
            "               Syria       0.21      0.18      0.19       278\n",
            "                Oman       0.25      0.18      0.21       355\n",
            "             Tunisia       0.15      0.05      0.08       172\n",
            "             Lebanon       0.17      0.08      0.11       157\n",
            "             Morocco       0.00      0.00      0.00       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.29      0.34      0.31       157\n",
            "              Kuwait       0.06      0.01      0.02       105\n",
            "               Libya       0.27      0.16      0.20       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.23      0.03      0.05       105\n",
            "           Palestine       0.00      0.00      0.00       104\n",
            "              Jordan       0.00      0.00      0.00       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.31      0.34      0.32        53\n",
            "\n",
            "            accuracy                           0.39      4997\n",
            "           macro avg       0.19      0.18      0.16      4997\n",
            "        weighted avg       0.31      0.39      0.33      4997\n",
            "\n",
            "\n",
            "Training Loss: 1.917\n",
            "Validation Loss: 2.131\n",
            "\n",
            " Epoch 13 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.54      0.93      0.68      1041\n",
            "                Iraq       0.36      0.45      0.40       663\n",
            "        Saudi_Arabia       0.31      0.54      0.39       519\n",
            "          Mauritania       0.50      0.02      0.04        53\n",
            "             Algeria       0.37      0.46      0.41       430\n",
            "               Syria       0.21      0.14      0.16       278\n",
            "                Oman       0.22      0.18      0.20       355\n",
            "             Tunisia       0.22      0.05      0.08       172\n",
            "             Lebanon       0.15      0.05      0.08       157\n",
            "             Morocco       0.33      0.02      0.04       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.35      0.22      0.27       157\n",
            "              Kuwait       0.04      0.01      0.02       105\n",
            "               Libya       0.36      0.15      0.21       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.43      0.11      0.18       105\n",
            "           Palestine       0.10      0.01      0.02       104\n",
            "              Jordan       0.25      0.01      0.02       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.37      0.28      0.32        53\n",
            "\n",
            "            accuracy                           0.40      4997\n",
            "           macro avg       0.24      0.17      0.17      4997\n",
            "        weighted avg       0.34      0.40      0.33      4997\n",
            "\n",
            "\n",
            "Training Loss: 1.911\n",
            "Validation Loss: 2.125\n",
            "\n",
            " Epoch 14 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.56      0.92      0.70      1041\n",
            "                Iraq       0.35      0.44      0.39       663\n",
            "        Saudi_Arabia       0.31      0.50      0.38       519\n",
            "          Mauritania       0.67      0.04      0.07        53\n",
            "             Algeria       0.35      0.48      0.40       430\n",
            "               Syria       0.21      0.15      0.18       278\n",
            "                Oman       0.23      0.22      0.23       355\n",
            "             Tunisia       0.33      0.02      0.03       172\n",
            "             Lebanon       0.23      0.06      0.09       157\n",
            "             Morocco       0.29      0.03      0.05       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.30      0.32      0.31       157\n",
            "              Kuwait       0.11      0.02      0.03       105\n",
            "               Libya       0.37      0.16      0.22       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.29      0.05      0.08       105\n",
            "           Palestine       0.00      0.00      0.00       104\n",
            "              Jordan       0.00      0.00      0.00       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.30      0.36      0.32        53\n",
            "\n",
            "            accuracy                           0.40      4997\n",
            "           macro avg       0.23      0.18      0.17      4997\n",
            "        weighted avg       0.34      0.40      0.34      4997\n",
            "\n",
            "\n",
            "Training Loss: 1.902\n",
            "Validation Loss: 2.132\n",
            "\n",
            " Epoch 15 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.59      0.90      0.72      1041\n",
            "                Iraq       0.35      0.47      0.40       663\n",
            "        Saudi_Arabia       0.29      0.64      0.39       519\n",
            "          Mauritania       0.38      0.06      0.10        53\n",
            "             Algeria       0.41      0.39      0.40       430\n",
            "               Syria       0.24      0.15      0.18       278\n",
            "                Oman       0.23      0.19      0.21       355\n",
            "             Tunisia       0.43      0.06      0.10       172\n",
            "             Lebanon       0.19      0.08      0.11       157\n",
            "             Morocco       0.38      0.04      0.07       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.41      0.17      0.24       157\n",
            "              Kuwait       0.00      0.00      0.00       105\n",
            "               Libya       0.33      0.23      0.27       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.39      0.07      0.11       105\n",
            "           Palestine       0.00      0.00      0.00       104\n",
            "              Jordan       0.25      0.01      0.02       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.29      0.30      0.30        53\n",
            "\n",
            "            accuracy                           0.40      4997\n",
            "           macro avg       0.25      0.18      0.17      4997\n",
            "        weighted avg       0.36      0.40      0.34      4997\n",
            "\n",
            "\n",
            "Training Loss: 1.888\n",
            "Validation Loss: 2.145\n",
            "\n",
            " Epoch 16 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.60      0.90      0.72      1041\n",
            "                Iraq       0.40      0.40      0.40       663\n",
            "        Saudi_Arabia       0.29      0.55      0.38       519\n",
            "          Mauritania       0.50      0.04      0.07        53\n",
            "             Algeria       0.38      0.49      0.43       430\n",
            "               Syria       0.22      0.15      0.18       278\n",
            "                Oman       0.20      0.28      0.23       355\n",
            "             Tunisia       0.25      0.02      0.04       172\n",
            "             Lebanon       0.20      0.05      0.08       157\n",
            "             Morocco       0.32      0.04      0.07       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.35      0.26      0.30       157\n",
            "              Kuwait       0.00      0.00      0.00       105\n",
            "               Libya       0.32      0.22      0.26       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.47      0.08      0.13       105\n",
            "           Palestine       0.00      0.00      0.00       104\n",
            "              Jordan       0.14      0.01      0.02       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.25      0.30      0.28        53\n",
            "\n",
            "            accuracy                           0.40      4997\n",
            "           macro avg       0.23      0.18      0.17      4997\n",
            "        weighted avg       0.35      0.40      0.35      4997\n",
            "\n",
            "\n",
            "Training Loss: 1.883\n",
            "Validation Loss: 2.126\n",
            "\n",
            " Epoch 17 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.60      0.90      0.72      1041\n",
            "                Iraq       0.38      0.42      0.40       663\n",
            "        Saudi_Arabia       0.28      0.66      0.39       519\n",
            "          Mauritania       0.56      0.09      0.16        53\n",
            "             Algeria       0.43      0.39      0.41       430\n",
            "               Syria       0.19      0.15      0.17       278\n",
            "                Oman       0.25      0.19      0.21       355\n",
            "             Tunisia       0.29      0.09      0.13       172\n",
            "             Lebanon       0.22      0.08      0.12       157\n",
            "             Morocco       0.48      0.06      0.10       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.33      0.21      0.26       157\n",
            "              Kuwait       0.05      0.01      0.02       105\n",
            "               Libya       0.32      0.22      0.26       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.57      0.08      0.13       105\n",
            "           Palestine       0.06      0.01      0.02       104\n",
            "              Jordan       0.40      0.02      0.04       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.26      0.32      0.29        53\n",
            "\n",
            "            accuracy                           0.40      4997\n",
            "           macro avg       0.27      0.19      0.18      4997\n",
            "        weighted avg       0.37      0.40      0.35      4997\n",
            "\n",
            "\n",
            "Training Loss: 1.877\n",
            "Validation Loss: 2.123\n",
            "\n",
            " Epoch 18 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.59      0.89      0.71      1041\n",
            "                Iraq       0.36      0.44      0.40       663\n",
            "        Saudi_Arabia       0.32      0.51      0.39       519\n",
            "          Mauritania       0.33      0.13      0.19        53\n",
            "             Algeria       0.33      0.49      0.40       430\n",
            "               Syria       0.18      0.15      0.16       278\n",
            "                Oman       0.24      0.18      0.21       355\n",
            "             Tunisia       0.35      0.03      0.06       172\n",
            "             Lebanon       0.26      0.10      0.15       157\n",
            "             Morocco       0.29      0.03      0.05       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.30      0.30      0.30       157\n",
            "              Kuwait       0.10      0.04      0.05       105\n",
            "               Libya       0.29      0.21      0.25       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.67      0.06      0.11       105\n",
            "           Palestine       0.00      0.00      0.00       104\n",
            "              Jordan       0.00      0.00      0.00       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.30      0.30      0.30        53\n",
            "\n",
            "            accuracy                           0.40      4997\n",
            "           macro avg       0.23      0.18      0.18      4997\n",
            "        weighted avg       0.34      0.40      0.34      4997\n",
            "\n",
            "\n",
            "Training Loss: 1.870\n",
            "Validation Loss: 2.140\n",
            "\n",
            " Epoch 19 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.59      0.91      0.71      1041\n",
            "                Iraq       0.32      0.56      0.41       663\n",
            "        Saudi_Arabia       0.31      0.52      0.39       519\n",
            "          Mauritania       0.30      0.06      0.10        53\n",
            "             Algeria       0.43      0.40      0.41       430\n",
            "               Syria       0.21      0.15      0.18       278\n",
            "                Oman       0.28      0.17      0.21       355\n",
            "             Tunisia       0.29      0.15      0.20       172\n",
            "             Lebanon       0.28      0.05      0.09       157\n",
            "             Morocco       0.35      0.03      0.06       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.34      0.23      0.27       157\n",
            "              Kuwait       0.07      0.03      0.04       105\n",
            "               Libya       0.36      0.15      0.21       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.48      0.10      0.16       105\n",
            "           Palestine       0.00      0.00      0.00       104\n",
            "              Jordan       0.13      0.02      0.03       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.30      0.26      0.28        53\n",
            "\n",
            "            accuracy                           0.40      4997\n",
            "           macro avg       0.24      0.18      0.18      4997\n",
            "        weighted avg       0.35      0.40      0.35      4997\n",
            "\n",
            "\n",
            "Training Loss: 1.855\n",
            "Validation Loss: 2.159\n",
            "\n",
            " Epoch 20 / 20\n",
            "  Batch    50  of    328.\n",
            "  Batch   100  of    328.\n",
            "  Batch   150  of    328.\n",
            "  Batch   200  of    328.\n",
            "  Batch   250  of    328.\n",
            "  Batch   300  of    328.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     79.\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "               Egypt       0.59      0.91      0.72      1041\n",
            "                Iraq       0.38      0.44      0.41       663\n",
            "        Saudi_Arabia       0.31      0.51      0.38       519\n",
            "          Mauritania       0.38      0.06      0.10        53\n",
            "             Algeria       0.40      0.41      0.40       430\n",
            "               Syria       0.19      0.15      0.17       278\n",
            "                Oman       0.22      0.31      0.25       355\n",
            "             Tunisia       0.28      0.09      0.14       172\n",
            "             Lebanon       0.21      0.07      0.11       157\n",
            "             Morocco       0.29      0.04      0.07       207\n",
            "            Djibouti       0.00      0.00      0.00        27\n",
            "United_Arab_Emirates       0.33      0.26      0.29       157\n",
            "              Kuwait       0.00      0.00      0.00       105\n",
            "               Libya       0.25      0.22      0.23       314\n",
            "             Bahrain       0.00      0.00      0.00        52\n",
            "               Qatar       0.00      0.00      0.00        52\n",
            "               Yemen       0.44      0.04      0.07       105\n",
            "           Palestine       0.00      0.00      0.00       104\n",
            "              Jordan       0.14      0.01      0.02       104\n",
            "             Somalia       0.00      0.00      0.00        49\n",
            "               Sudan       0.33      0.30      0.31        53\n",
            "\n",
            "            accuracy                           0.40      4997\n",
            "           macro avg       0.23      0.18      0.17      4997\n",
            "        weighted avg       0.34      0.40      0.35      4997\n",
            "\n",
            "\n",
            "Training Loss: 1.848\n",
            "Validation Loss: 2.156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrggXiTwRVwJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtwEjwioxiYj",
        "outputId": "fbf456fe-233d-4a19-aa42-93ed36d867fb"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " AraBert.ipynb                    LSTM_old.ipynb\n",
            " \u001b[0m\u001b[01;34maravec\u001b[0m/                         'prepare for trainning.ipynb'\n",
            " \u001b[01;34mdata\u001b[0m/                            README.md\n",
            " environment.yml                  removed_stopwords_from_tweet.txt\n",
            "'Explore Data.ipynb'              requirements.txt\n",
            "'formal clitics stop words.txt'   SDG.ipynb\n",
            " LICENSE                          utilities.py\n",
            " LSTM.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsEX62o_xi_0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}