Mawdoo3 AI~\cite{talafha2020multidialect} which have achieved the wining solution with a micro-averaged F1-score of 26.78\% on the subtask 1 by using the pretrained Ara-bicBERT~\cite{safaya2020kuisail} which trained on around 93 GB of Arabic content crawled from around the internet and further pre-training Ara-bicBERT on the unlabeled 10M tweets released by the NADI organizers, for 3 epochs. The contributors have improved the model accuracy by using ensemble techniques from the voting of 4 models that were trained with different maximum sequence lengths. The voting step was accomplished by taking the element-wise average of the predicted probabilities per classifier. \\BERT NGRAMS~\cite{el-mekki-etal-2020-weighted} the second wining solution which have achieved a micro-averaged F1-score of 25.99\% for the Country-Level Identification and 6.39\% on the Province-Level Identification. The researchers used an ensemble technique consist of 2 models voting, pre-trained Arabic BERT (AraBERT) and TF-IDF N-gram model for word level and character level concatenated together as one model called N-gram model. The data preparation phase was performed on the models level respectively. For the AraBERT, The researchers have followed the steps of Detecting emojis within a tweet,  Substituting emojis with the special token [MASK] then Tokenizing the output sentence.
The data prepration for NGRAM model was done on 3 stages Data Augmentation, Data Cleaning and Feature Extraction.
The researchers have applied the ensemble approach where AraBERT model results have classified the tweet into two segments per each country.
The first one contains tweetâ€™s tokens, while the second segment contains the tokens of the Arabic meanings of detected emojis. The researchers have represented the tweet by the output of a global max pooling function applied on AraBERT token representation. The probability that a tweet belongs to a country is computed by a softmax function that takes the tweet representation as input.
The researchers then used stochastic gradient descent (SGD) classifier that was trained on the concatenation of TF-IDF vectors of the word-level n-grams and character-level n-grams. There have been some challenges faced due to the significantly unbalancing distribution of tweets dataset between countries, the etymological closeness of the Arabic dialects and the predominance of one or more topics in a set of tweets that belong to the same country (Topic-Biased).